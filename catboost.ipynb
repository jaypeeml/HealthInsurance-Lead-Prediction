{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "catboost.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idbk5ptumRu2"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ansqTGimX_t"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/drive\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9KfggHGmmdi"
      },
      "source": [
        "# !pip install catboost"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9RRm0m-ImRu-"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "pd.set_option('display.max_columns', 100)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from itertools import combinations"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTUPb-JgmRvB"
      },
      "source": [
        "### Read data and perform basic preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1L8QM6fTmRvC"
      },
      "source": [
        "def process_data(DATA_DIR):\n",
        "    \n",
        "    train = pd.read_csv(DATA_DIR+\"train.csv\")\n",
        "    test = pd.read_csv(DATA_DIR+\"test.csv\")\n",
        "    \n",
        "    #Removes train rows which has Region_Code not present in test set\n",
        "    test_region_list=test['Region_Code'].tolist()\n",
        "    train=train[train['Region_Code'].isin(test_region_list)]\n",
        "    \n",
        "    train['train_or_test']='train'\n",
        "    test['train_or_test']='test'\n",
        "    df=pd.concat([train,test])\n",
        "    \n",
        "    df['Holding_Policy_Duration']=(df['Holding_Policy_Duration'].replace(['14+'],[15])).astype(float)\n",
        "    \n",
        "    le = LabelEncoder()\n",
        "    for col in ['City_Code','Accomodation_Type','Reco_Insurance_Type','Health Indicator','Is_Spouse']:\n",
        "        df[col]=  df[col].astype('str')\n",
        "        df[col]= le.fit_transform(df[col])\n",
        "        \n",
        "\n",
        "    \n",
        "    return train,test,df"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZtBXYrqmRvC"
      },
      "source": [
        "### Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qGTtatj0mRvD"
      },
      "source": [
        "def frequency_encoding(column_name,output_column_name,df):\n",
        "    fe_pol = (df.groupby(column_name).size()) / len(df)\n",
        "    df[output_column_name] = df[column_name].apply(lambda x : fe_pol[x])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0RSab0PmmRvD"
      },
      "source": [
        "def frequency_encoding(column_name,output_column_name,df):\n",
        "    fe_pol = (df.groupby(column_name).size()) / len(df)\n",
        "    df[output_column_name] = df[column_name].apply(lambda x : fe_pol[x])\n",
        "\n",
        "\n",
        "def feature_engineering(df):\n",
        "    le = LabelEncoder()\n",
        "    \n",
        "     #Interaction Feature (Combining 2 categorical features and performing frequency encoding)\n",
        "        \n",
        "    cat_features=[]\n",
        "    le_features=[]\n",
        "    columns=['City_Code','Accomodation_Type','Reco_Insurance_Type','Health Indicator','Is_Spouse','Region_Code','Holding_Policy_Type','Reco_Policy_Cat']\n",
        "\n",
        "    comb = combinations(columns, 2) \n",
        "\n",
        "    for i in list(comb):  \n",
        "        df[f'{i[0]}_{i[1]}']=df[i[0]].astype(str)+'_'+df[i[1]].astype(str)\n",
        "        df[f'{i[0]}_{i[1]}_le']=le.fit_transform(df[f'{i[0]}_{i[1]}'])\n",
        "        le_features.append(f'{i[0]}_{i[1]}_le')\n",
        "        frequency_encoding(f'{i[0]}_{i[1]}',f'{i[0]}_{i[1]}',df)\n",
        "        cat_features.append(f'{i[0]}_{i[1]}')   \n",
        "        \n",
        "    #Frequency Encoding\n",
        "    \n",
        "    frequency_encoding('Region_Code','Region_Code_fe',df)\n",
        "    frequency_encoding('Reco_Policy_Cat','Reco_Policy_Cat_fe',df)\n",
        "    \n",
        "    #Deriving characteristics of each city by creating aggregate features\n",
        "    \n",
        "    city_aggregate_features = df.groupby(['City_Code']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n",
        "                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std'], \n",
        "                                                     'Region_Code': ['nunique','count'], \n",
        "                                                     'Accomodation_Type': ['nunique','count'],\n",
        "                                                     'Reco_Insurance_Type': ['nunique','count'] ,\n",
        "                                                     'Health Indicator': ['nunique','count'] ,\n",
        "                                                     'Holding_Policy_Type': ['nunique','count'] ,\n",
        "                                                     'Reco_Policy_Cat': ['nunique','count'] ,\n",
        "                                                     })\n",
        "    city_aggregate_features.columns = ['city_aggregate_features' + '_'.join(c).strip('_') for c in city_aggregate_features.columns]\n",
        "    df = pd.merge(df, city_aggregate_features, on = ['City_Code'], how='left')\n",
        "\n",
        " \n",
        "    city_region_aggregate_features = df.groupby(['City_Code','Region_Code']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n",
        "                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std'],  \n",
        "                                                     'Accomodation_Type': ['nunique','count'],\n",
        "                                                     'Reco_Insurance_Type': ['nunique','count'] ,\n",
        "                                                     'Health Indicator': ['nunique','count'] ,\n",
        "                                                     'Holding_Policy_Type': ['nunique','count'] ,\n",
        "                                                     'Reco_Policy_Cat': ['nunique','count'] ,\n",
        "                                                     })\n",
        "    city_region_aggregate_features.columns = ['city_region_aggregate_features' + '_'.join(c).strip('_') for c in city_region_aggregate_features.columns]\n",
        "    df = pd.merge(df, city_region_aggregate_features, on = ['City_Code','Region_Code'], how='left')\n",
        "\n",
        "    city_recopolicycat_aggregate_features = df.groupby(['City_Code','Reco_Policy_Cat']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n",
        "                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std'], \n",
        "                                                     'Region_Code': ['nunique','count'], \n",
        "                                                     'Accomodation_Type': ['nunique','count'],\n",
        "                                                     'Reco_Insurance_Type': ['nunique','count'] ,\n",
        "                                                     'Health Indicator': ['nunique','count'] ,\n",
        "                                                     'Holding_Policy_Type': ['nunique','count'] \n",
        "                                                     })\n",
        "    city_recopolicycat_aggregate_features.columns = ['city_recopolicycat_aggregate_features' + '_'.join(c).strip('_') for c in city_recopolicycat_aggregate_features.columns]\n",
        "    df = pd.merge(df, city_recopolicycat_aggregate_features, on = ['City_Code','Reco_Policy_Cat'], how='left')\n",
        "    \n",
        "    city_regioncoderecopolicycat_aggregate_features = df.groupby(['City_Code','Region_Code_Reco_Policy_Cat']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n",
        "                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std'], \n",
        "                                                     'Region_Code': ['nunique','count'], \n",
        "                                                     'Accomodation_Type': ['nunique','count'],\n",
        "                                                     'Reco_Insurance_Type': ['nunique','count'] ,\n",
        "                                                     'Health Indicator': ['nunique','count'] ,\n",
        "                                                     'Holding_Policy_Type': ['nunique','count'] ,\n",
        "                                                     'Reco_Policy_Cat': ['nunique','count'] ,\n",
        "                                                     })\n",
        "\n",
        "    city_regioncoderecopolicycat_aggregate_features.columns = ['city_regioncoderecopolicycat_aggregate_features' + '_'.join(c).strip('_') for c in city_regioncoderecopolicycat_aggregate_features.columns]\n",
        "    df = pd.merge(df, city_regioncoderecopolicycat_aggregate_features, on = ['City_Code','Region_Code_Reco_Policy_Cat'], how='left')\n",
        "    \n",
        "    for i in cat_features:\n",
        "        df[f'city_{i}_max']=df.groupby('City_Code')[i].transform('max')\n",
        "        df[f'city_{i}_min']=df.groupby('City_Code')[i].transform('min')\n",
        "        df[f'city_{i}_mean']=df.groupby('City_Code')[i].transform('mean')\n",
        "        df[f'city_{i}_std']=df.groupby('City_Code')[i].transform('std')\n",
        "\n",
        "    \n",
        "        df[f'city_region_{i}_max']=df.groupby(['City_Code','Region_Code'])[i].transform('max')\n",
        "        df[f'city_region_{i}_min']=df.groupby(['City_Code','Region_Code'])[i].transform('min')\n",
        "        df[f'city_region_{i}_mean']=df.groupby(['City_Code','Region_Code'])[i].transform('mean')\n",
        "        df[f'city_region_{i}_std']=df.groupby(['City_Code','Region_Code'])[i].transform('std')\n",
        "\n",
        "    \n",
        "        df[f'city_recopolicycat_{i}_max']=df.groupby(['City_Code','Reco_Policy_Cat'])[i].transform('max')\n",
        "        df[f'city_recopolicycat_{i}_min']=df.groupby(['City_Code','Reco_Policy_Cat'])[i].transform('min')\n",
        "        df[f'city_recopolicycat_{i}_mean']=df.groupby(['City_Code','Reco_Policy_Cat'])[i].transform('mean')\n",
        "        df[f'city_recopolicycat_{i}_std']=df.groupby(['City_Code','Reco_Policy_Cat'])[i].transform('std')\n",
        "        \n",
        "    \n",
        "    #features on reco_policy_cat\n",
        "    \n",
        "    recopolicycat_aggregate_features = df.groupby(['Reco_Policy_Cat']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n",
        "                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std','sum'],   \n",
        "                                                     'Region_Code': ['nunique','count'], \n",
        "                                                     'Accomodation_Type': ['nunique'],\n",
        "                                                     'Reco_Insurance_Type': ['nunique'] ,\n",
        "                                                     'Health Indicator': ['nunique','count'] ,\n",
        "                                                     'Holding_Policy_Type': ['nunique','count'] ,\n",
        "                                                     'City_Code': ['nunique','count'] ,\n",
        "                                                     })\n",
        "    recopolicycat_aggregate_features.columns = ['recopolicycat_aggregate_features' + '_'.join(c).strip('_') for c in recopolicycat_aggregate_features.columns]\n",
        "    df = pd.merge(df, recopolicycat_aggregate_features, on = ['Reco_Policy_Cat'], how='left')\n",
        "        \n",
        "        \n",
        "\n",
        "    #features on Holding_Policy_Type \n",
        "    \n",
        "    holdingpolicytype_aggregate_features = df.groupby(['Holding_Policy_Type']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n",
        "                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std'], \n",
        "                                                     'Region_Code': ['nunique','count'], \n",
        "                                                     'Accomodation_Type': ['nunique','count'],\n",
        "                                                     'Reco_Insurance_Type': ['nunique','count'] ,\n",
        "                                                     'Health Indicator': ['nunique','count'] ,\n",
        "                                                     'City_Code': ['nunique','count'] ,\n",
        "                                                     })\n",
        "    holdingpolicytype_aggregate_features.columns = ['holdingpolicytype_aggregate_features' + '_'.join(c).strip('_') for c in holdingpolicytype_aggregate_features.columns]\n",
        "    df = pd.merge(df, holdingpolicytype_aggregate_features, on = ['Holding_Policy_Type'], how='left')\n",
        "    \n",
        "    #Deriving characteristics of Accomodation_Type by creating aggregate features\n",
        "    \n",
        "    Accomodation_Type_aggregate_features = df.groupby(['Accomodation_Type']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n",
        "                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std','sum'],   \n",
        "                                                     'Region_Code': ['nunique','count'], \n",
        "                                                     'Reco_Insurance_Type': ['nunique'] ,\n",
        "                                                     'Health Indicator': ['nunique','count'] ,\n",
        "                                                     'Holding_Policy_Type': ['nunique','count'] ,\n",
        "                                                     'City_Code': ['nunique','count'] ,\n",
        "                                                     })\n",
        "    Accomodation_Type_aggregate_features.columns = ['Accomodation_Type_aggregate_features' + '_'.join(c).strip('_') for c in Accomodation_Type_aggregate_features.columns]\n",
        "    df = pd.merge(df, Accomodation_Type_aggregate_features, on = ['Accomodation_Type'], how='left')\n",
        "    \n",
        "    #Deriving characteristics of Interaction_features by creating aggregate features (These interaction feature are selected for aggregating based on its feature importance)\n",
        "    \n",
        "    Region_CodeReco_Policy_Cat_grpd = df.groupby(['Region_Code_Reco_Policy_Cat']).agg({ 'Reco_Policy_Premium': ['mean', 'max', 'min', 'std']})                                                              \n",
        "                                                     \n",
        "    Region_CodeReco_Policy_Cat_grpd.columns = ['grpd_by_Region_Code_Reco_Policy_Cat_' + '_'.join(c).strip('_') for c in Region_CodeReco_Policy_Cat_grpd.columns]\n",
        "    df = pd.merge(df, Region_CodeReco_Policy_Cat_grpd, on = ['Region_Code_Reco_Policy_Cat'], how='left')\n",
        "\n",
        "\n",
        "    City_CodeRegion_Code_grpd = df.groupby(['City_Code_Region_Code']).agg({ 'Reco_Policy_Premium': ['mean', 'max', 'min', 'std']})                                                              \n",
        "                                                     \n",
        "    City_CodeRegion_Code_grpd.columns = ['grpd_by_City_CodeRegion_Code_' + '_'.join(c).strip('_') for c in City_CodeRegion_Code_grpd.columns]\n",
        "    df = pd.merge(df, City_CodeRegion_Code_grpd, on = ['City_Code_Region_Code'], how='left')\n",
        "\n",
        "\n",
        "    City_CodeReco_Policy_Cat_grpd = df.groupby(['City_Code_Reco_Policy_Cat']).agg({ 'Reco_Policy_Premium': ['mean', 'max', 'min', 'std']})                                                              \n",
        "                                                     \n",
        "    City_CodeReco_Policy_Cat_grpd.columns = ['grpd_by_City_CodeReco_Policy_Cat_' + '_'.join(c).strip('_') for c in City_CodeReco_Policy_Cat_grpd.columns]\n",
        "    df = pd.merge(df, City_CodeReco_Policy_Cat_grpd, on = ['City_Code_Reco_Policy_Cat'], how='left')\n",
        "\n",
        "\n",
        "    Holding_Policy_TypeReco_Policy_Cat_grpd = df.groupby(['Holding_Policy_Type_Reco_Policy_Cat']).agg({ 'Reco_Policy_Premium': ['mean', 'max', 'min', 'std']})                                                              \n",
        "                                                     \n",
        "    Holding_Policy_TypeReco_Policy_Cat_grpd.columns = ['grpd_by_Holding_Policy_TypeReco_Policy_Cat_' + '_'.join(c).strip('_') for c in Holding_Policy_TypeReco_Policy_Cat_grpd.columns]\n",
        "    df = pd.merge(df, Holding_Policy_TypeReco_Policy_Cat_grpd, on = ['Holding_Policy_Type_Reco_Policy_Cat'], how='left')\n",
        "    \n",
        "    return df,le_features\n",
        "    "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZXh_NdNmRvN"
      },
      "source": [
        "### Remove unnecessary columns and prepare the train and test data for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "paRIPGYVmRvP"
      },
      "source": [
        "def preparedatafortraining(df,train,test):\n",
        "    \n",
        "    train=df.loc[df.train_or_test.isin(['train'])]\n",
        "    test=df.loc[df.train_or_test.isin(['test'])]\n",
        "    \n",
        "    drop_columns={'ID','Response','Upper_Age','train_or_test'}\n",
        "    \n",
        "    target=['Response']\n",
        "    \n",
        "    x=train.drop(columns=drop_columns,axis=1)\n",
        "    y=train[target]\n",
        "    x_test=test.drop(columns=drop_columns,axis=1)\n",
        "    \n",
        "    print(x.shape)\n",
        "    \n",
        "    return x,y,x_test"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oR-Nc-xXmRvQ"
      },
      "source": [
        "### Save Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4yIVa13WmRvR"
      },
      "source": [
        "def savedata(**DATA_DIR):\n",
        "    \n",
        "    train,test,df=process_data(\"/content/drive/My Drive/Health Insurance Lead Prediction/Data/\")\n",
        "    df,cat_features=feature_engineering(df)\n",
        "    x_train,y_train,x_test=preparedatafortraining(df,train,test)\n",
        "    \n",
        "    #x_train.to_pickle(\"x_train_lgbm.pkl\")\n",
        "    #y_train.to_pickle(\"y_train_lgbm.pkl\")\n",
        "    #x_test.to_pickle(\"x_test_lgbm.pkl\")\n",
        "    \n",
        "    return x_train,y_train,x_test,cat_features"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNjBolOfmRvR"
      },
      "source": [
        "### Train CatBoost Model and save the validation and test set prediction for ensembling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XdKXbJEnmRvR"
      },
      "source": [
        "def catboost_model():\n",
        "    \n",
        "    x,y,x_test,cat_features=savedata()\n",
        "     \n",
        "    err = [] \n",
        "\n",
        "    oofs = np.zeros(shape=(len(x)))\n",
        "    preds = np.zeros(shape=(len(x_test)))\n",
        "\n",
        "    Folds=8\n",
        "\n",
        "    fold = StratifiedKFold(n_splits=Folds, shuffle=True, random_state=2020)\n",
        "    i = 1\n",
        "\n",
        "    for train_index, test_index in fold.split(x, y):\n",
        "        x_train, x_val = x.iloc[train_index], x.iloc[test_index]\n",
        "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
        "    \n",
        "        m =  CatBoostClassifier(n_estimators=10000,random_state=2020,eval_metric='AUC')\n",
        "    \n",
        "        m.fit(x_train, y_train,eval_set=[(x_val, y_val)], early_stopping_rounds=30,verbose=100,cat_features=cat_features)\n",
        "    \n",
        "        pred_y = m.predict_proba(x_val)[:,1]\n",
        "        oofs[test_index] = pred_y\n",
        "        print(i, \" err_cat: \", roc_auc_score(y_val,pred_y))\n",
        "        err.append(roc_auc_score(y_val,pred_y))\n",
        "        preds+= m.predict_proba(x_test)[:,1]\n",
        "        i = i + 1\n",
        "    preds=preds/Folds\n",
        "    \n",
        "    print(f\"Average StratifiedKFold Score : {sum(err)/Folds} \")\n",
        "    oof_score = roc_auc_score(y, oofs)\n",
        "    print(f'\\nOOF Auc is : {oof_score}')\n",
        "    \n",
        "    oofs=pd.DataFrame(oofs,columns=['catboostoof'])\n",
        "    preds=pd.DataFrame(preds,columns=['catboostpred'])\n",
        "    \n",
        "    x_train.to_csv('x_train.csv',index=False)\n",
        "    x_val.to_csv('x_val.csv',index=False)\n",
        "\n",
        "    oofs.to_csv('catboostoof.csv',index=False)\n",
        "    preds.to_csv('catboostpred.csv',index=False)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LCMbRFYjmRvS"
      },
      "source": [
        "catboost_model()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}